复制：

一条消息只有被“in sync” list里的所有follower都从leader复制过去才会被认为已提交。
这样就避免了部分数据被写进了leader，还没来得及被任何follower复制就宕机了，而造成数据丢失（consumer无法消费这些数据）。
而对于producer而言，它可以选择是否等待消息commit，这可以通过 request.required.acks 来设置。
这种机制确保了只要“in sync” list有一个或以上的flollower，一条被commit的消息就不会丢失。

这里的复制机制即不是同步复制，也不是单纯的异步复制。事实上，同步复制要求“活着的”follower都复制完，
这条消息才会被认为commit，这种复制方式极大的影响了吞吐率（高吞吐率是Kafka非常重要的一个特性）。
而异步复制方式下，follower异步的从leader复制数据，数据只要被leader写入log就被认为已经commit，
这种情况下如果follwer都落后于leader，而leader突然宕机，
则会丢失数据。而Kafka的这种使用“in sync” list的方式则很好的均衡了确保数据不丢失以及吞吐率。
follower可以批量的从leader复制数据，这样极大的提高复制性能（批量写磁盘），
极大减少了follower与leader的差距（前文有说到，只要follower落后leader不太远，则被认为在“in sync” list里）。

上文说明了Kafka是如何做replication的，另外一个很重要的问题是当leader宕机了，
怎样在follower中选举出新的leader。因为follower可能落后许多或者crash了，
所以必须确保选择“最新”的follower作为新的leader。一个基本的原则就是，如果leader不在了，
新的leader必须拥有原来的leader commit的所有消息。这就需要作一个折衷，
如果leader在标明一条消息被commit前等待更多的follower确认，那在它die之后就有更多的follower可以作为新的leader，
但这也会造成吞吐率的下降。


A message is considered “committed” when all in sync replicas for that partition have applied it to their log.
Only committed messages are ever given out to the consumer.
This means that the consumer need not worry about potentially seeing a message that could be lost if the leader fails. 
Producers, on the other hand, have the option of either waiting for the message to be committed or not,
depending on their preference for tradeoff between latency and durability. 
This preference is controlled by the request.required.acks setting that the producer uses.
